Decision Tree Feature Importance Analysis
==================================================

Tree Parameters:
ccp_alpha: 0.0
class_weight: None
criterion: gini
max_depth: None
max_features: None
max_leaf_nodes: None
min_impurity_decrease: 0.0
min_samples_leaf: 1
min_samples_split: 2
min_weight_fraction_leaf: 0.0
monotonic_cst: None
random_state: 42
splitter: best

Feature Importance Scores:
AveragePrice: 0.0447
4225: 0.0461
4046: 0.0550
4770: 0.1148
Total Volume: 0.7395

Tree Properties:
Number of nodes: 711
Tree depth: 20

Data Properties:
Training samples: 18250
Features: 5
Missing values (before filling):
  AveragePrice: 48 (0.3%)
